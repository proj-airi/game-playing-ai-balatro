#!/usr/bin/env python3
"""
å±å¹•æ£€æµ‹æ¼”ç¤ºç¨‹åº
å®æ—¶æ•æ‰å±å¹•å¹¶ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ£€æµ‹æ ‡æ³¨

Author: RainbowBird
"""

import os
import time
import cv2
import numpy as np
from typing import Optional

from screen_capture import ScreenCapture
from yolo_detector import YOLODetector


class ScreenDetectionDemo:
    """å±å¹•æ£€æµ‹æ¼”ç¤ºç±»"""
    
    def __init__(self, model_path: str, use_onnx: bool = False):
        """
        åˆå§‹åŒ–æ¼”ç¤ºç¨‹åº
        
        Args:
            model_path: YOLOæ¨¡å‹è·¯å¾„
            use_onnx: æ˜¯å¦ä½¿ç”¨ONNXæ¨¡å‹
        """
        self.model_path = model_path
        self.use_onnx = use_onnx
        
        # åˆå§‹åŒ–æ¨¡å—
        print("ğŸ¤– åˆå§‹åŒ–å±å¹•æ£€æµ‹æ¼”ç¤º...")
        
        # åˆå§‹åŒ–å±å¹•æ•æ‰
        print("ğŸ“¸ åˆå§‹åŒ–å±å¹•æ•æ‰...")
        self.screen_capture = ScreenCapture()
        
        # åˆå§‹åŒ–YOLOæ£€æµ‹å™¨
        print("ğŸ¯ åˆå§‹åŒ–YOLOæ£€æµ‹å™¨...")
        self.yolo_detector = YOLODetector(model_path, use_onnx=use_onnx)
        
        # æ£€æµ‹å‚æ•°
        self.confidence_threshold = 0.5
        self.iou_threshold = 0.45
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.frame_count = 0
        self.detection_count = 0
        self.start_time = time.time()
        
        print("âœ… åˆå§‹åŒ–å®Œæˆ")
    
    def set_detection_params(self, confidence: float = 0.5, iou: float = 0.45):
        """è®¾ç½®æ£€æµ‹å‚æ•°"""
        self.confidence_threshold = confidence
        self.iou_threshold = iou
        print(f"ğŸ¯ æ£€æµ‹å‚æ•°: ç½®ä¿¡åº¦={confidence}, IoU={iou}")
    
    def select_region(self) -> bool:
        """é€‰æ‹©æ£€æµ‹åŒºåŸŸ"""
        print("ğŸ¯ è¯·é€‰æ‹©è¦æ£€æµ‹çš„å±å¹•åŒºåŸŸ...")
        return self.screen_capture.select_region_interactive()
    
    def run_single_detection(self, save_result: bool = True) -> bool:
        """è¿è¡Œå•æ¬¡æ£€æµ‹"""
        print("ğŸ“¸ æ•æ‰å±å¹•...")
        
        # æ•æ‰å±å¹•
        frame = self.screen_capture.capture_once()
        if frame is None:
            print("âŒ å±å¹•æ•æ‰å¤±è´¥")
            return False
        
        print(f"âœ… æ•æ‰æˆåŠŸï¼Œå›¾åƒå°ºå¯¸: {frame.shape}")
        
        # è¿è¡Œæ£€æµ‹
        print("ğŸ” è¿è¡ŒYOLOæ£€æµ‹...")
        detections = self.yolo_detector.detect(
            frame,
            confidence_threshold=self.confidence_threshold,
            iou_threshold=self.iou_threshold
        )
        
        print(f"ğŸ¯ æ£€æµ‹åˆ° {len(detections)} ä¸ªå¯¹è±¡:")
        for i, det in enumerate(detections):
            print(f"  {i+1}. {det.class_name} (ç½®ä¿¡åº¦: {det.confidence:.3f}) ä½ç½®: {det.bbox}")
        
        # å¯è§†åŒ–ç»“æœ
        vis_frame = self.yolo_detector.visualize_detections(frame, detections)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        info_text = [
            f"æ£€æµ‹å¯¹è±¡: {len(detections)}",
            f"ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}",
            f"IoUé˜ˆå€¼: {self.iou_threshold}",
            f"æ¨¡å‹: {'ONNX' if self.use_onnx else 'PyTorch'}"
        ]
        
        for i, text in enumerate(info_text):
            cv2.putText(vis_frame, text, (10, 30 + i * 25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # æ˜¾ç¤ºç»“æœ
        cv2.imshow("å°ä¸‘ç‰Œæ£€æµ‹ç»“æœ", vis_frame)
        
        # ä¿å­˜ç»“æœ
        if save_result:
            timestamp = int(time.time())
            original_filename = f"screen_capture_{timestamp}.png"
            detection_filename = f"detection_result_{timestamp}.png"
            
            cv2.imwrite(original_filename, frame)
            cv2.imwrite(detection_filename, vis_frame)
            
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜:")
            print(f"  åŸå§‹å›¾åƒ: {original_filename}")
            print(f"  æ£€æµ‹ç»“æœ: {detection_filename}")
        
        print("\næŒ‰ä»»æ„é”®ç»§ç»­ï¼ŒæŒ‰ 'q' é€€å‡º...")
        key = cv2.waitKey(0) & 0xFF
        cv2.destroyAllWindows()
        
        return key != ord('q')
    
    def run_continuous_detection(self, fps: int = 2) -> None:
        """è¿è¡Œè¿ç»­æ£€æµ‹"""
        print(f"ğŸš€ å¼€å§‹è¿ç»­æ£€æµ‹ (FPS: {fps})...")
        print("æ§åˆ¶é”®:")
        print("  'q' - é€€å‡º")
        print("  's' - ä¿å­˜å½“å‰å¸§")
        print("  '+' - æé«˜ç½®ä¿¡åº¦é˜ˆå€¼")
        print("  '-' - é™ä½ç½®ä¿¡åº¦é˜ˆå€¼")
        print("  ç©ºæ ¼ - æš‚åœ/ç»§ç»­")
        
        frame_time = 1.0 / fps
        paused = False
        
        while True:
            if not paused:
                loop_start = time.time()
                
                # æ•æ‰å±å¹•
                frame = self.screen_capture.capture_once()
                if frame is None:
                    continue
                
                self.frame_count += 1
                
                # è¿è¡Œæ£€æµ‹
                detections = self.yolo_detector.detect(
                    frame,
                    confidence_threshold=self.confidence_threshold,
                    iou_threshold=self.iou_threshold
                )
                
                self.detection_count += len(detections)
                
                # å¯è§†åŒ–ç»“æœ
                vis_frame = self.yolo_detector.visualize_detections(frame, detections)
                
                # æ·»åŠ å®æ—¶ä¿¡æ¯
                runtime = time.time() - self.start_time
                avg_fps = self.frame_count / runtime if runtime > 0 else 0
                avg_detections = self.detection_count / self.frame_count if self.frame_count > 0 else 0
                
                info_text = [
                    f"æ£€æµ‹å¯¹è±¡: {len(detections)}",
                    f"ç½®ä¿¡åº¦: {self.confidence_threshold:.2f}",
                    f"å¹³å‡FPS: {avg_fps:.1f}",
                    f"å¹³å‡æ£€æµ‹æ•°: {avg_detections:.1f}",
                    f"æ€»å¸§æ•°: {self.frame_count}",
                    "ç©ºæ ¼:æš‚åœ q:é€€å‡º s:ä¿å­˜ +/-:è°ƒæ•´ç½®ä¿¡åº¦"
                ]
                
                for i, text in enumerate(info_text):
                    color = (0, 255, 0) if i < 4 else (255, 255, 255)
                    cv2.putText(vis_frame, text, (10, 30 + i * 25),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)
                
                # æ˜¾ç¤ºç»“æœ
                cv2.imshow("å°ä¸‘ç‰Œå®æ—¶æ£€æµ‹", vis_frame)
                
                # æ§åˆ¶å¸§ç‡
                elapsed = time.time() - loop_start
                sleep_time = frame_time - elapsed
                if sleep_time > 0:
                    time.sleep(sleep_time)
            
            # å¤„ç†æŒ‰é”®
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                break
            elif key == ord('s'):
                # ä¿å­˜å½“å‰å¸§
                timestamp = int(time.time())
                filename = f"realtime_detection_{timestamp}.png"
                cv2.imwrite(filename, vis_frame)
                print(f"ğŸ’¾ å·²ä¿å­˜: {filename}")
            elif key == ord('+') or key == ord('='):
                # æé«˜ç½®ä¿¡åº¦
                self.confidence_threshold = min(0.95, self.confidence_threshold + 0.05)
                print(f"ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold:.2f}")
            elif key == ord('-'):
                # é™ä½ç½®ä¿¡åº¦
                self.confidence_threshold = max(0.1, self.confidence_threshold - 0.05)
                print(f"ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold:.2f}")
            elif key == ord(' '):
                # æš‚åœ/ç»§ç»­
                paused = not paused
                status = "æš‚åœ" if paused else "ç»§ç»­"
                print(f"â¸ï¸ {status}")
        
        cv2.destroyAllWindows()
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        runtime = time.time() - self.start_time
        print(f"\nğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
        print(f"  è¿è¡Œæ—¶é—´: {runtime:.1f}ç§’")
        print(f"  æ€»å¸§æ•°: {self.frame_count}")
        print(f"  æ€»æ£€æµ‹æ•°: {self.detection_count}")
        print(f"  å¹³å‡FPS: {self.frame_count / runtime:.1f}")
        print(f"  å¹³å‡æ£€æµ‹æ•°/å¸§: {self.detection_count / self.frame_count:.1f}")


def find_model_path() -> Optional[str]:
    """æŸ¥æ‰¾å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶"""
    model_paths = [
        "../runs/v2-balatro-entities-2000-epoch/weights/best.pt",
        "../models/games-balatro-2024-yolo-entities-detection/model.pt",
        "../runs/v2-balatro-entities/weights/best.pt",
        "runs/v2-balatro-entities-2000-epoch/weights/best.pt",
        "models/games-balatro-2024-yolo-entities-detection/model.pt"
    ]
    
    for path in model_paths:
        if os.path.exists(path):
            return path
    
    return None


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸƒ å°ä¸‘ç‰Œå±å¹•æ£€æµ‹æ¼”ç¤º")
    print("=" * 50)
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    model_path = find_model_path()
    if not model_path:
        print("âŒ æœªæ‰¾åˆ°YOLOæ¨¡å‹æ–‡ä»¶")
        print("\nè¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨äºä»¥ä¸‹ä½ç½®ä¹‹ä¸€:")
        print("  - ../runs/v2-balatro-entities-2000-epoch/weights/best.pt")
        print("  - ../models/games-balatro-2024-yolo-entities-detection/model.pt")
        return
    
    print(f"âœ… æ‰¾åˆ°æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºæ¼”ç¤ºç¨‹åº
    try:
        demo = ScreenDetectionDemo(model_path, use_onnx=False)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # é€‰æ‹©æ£€æµ‹åŒºåŸŸ
    if not demo.select_region():
        print("âŒ æœªé€‰æ‹©æ£€æµ‹åŒºåŸŸï¼Œé€€å‡º")
        return
    
    # è®¾ç½®æ£€æµ‹å‚æ•°
    print("\nğŸ¯ è®¾ç½®æ£€æµ‹å‚æ•°...")
    confidence = input("ç½®ä¿¡åº¦é˜ˆå€¼ (0.1-0.9, é»˜è®¤0.5): ").strip()
    if confidence:
        try:
            demo.set_detection_params(confidence=float(confidence))
        except ValueError:
            print("âš ï¸ æ— æ•ˆè¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    # é€‰æ‹©è¿è¡Œæ¨¡å¼
    print("\nğŸš€ é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("  1. å•æ¬¡æ£€æµ‹")
    print("  2. è¿ç»­æ£€æµ‹")
    
    mode = input("è¯·é€‰æ‹© (1/2, é»˜è®¤2): ").strip()
    
    if mode == "1":
        # å•æ¬¡æ£€æµ‹æ¨¡å¼
        print("\nğŸ“¸ å•æ¬¡æ£€æµ‹æ¨¡å¼")
        while True:
            if not demo.run_single_detection():
                break
    else:
        # è¿ç»­æ£€æµ‹æ¨¡å¼
        print("\nğŸ¥ è¿ç»­æ£€æµ‹æ¨¡å¼")
        fps = input("æ£€æµ‹å¸§ç‡ (1-10, é»˜è®¤2): ").strip()
        if fps:
            try:
                fps = int(fps)
                fps = max(1, min(10, fps))
            except ValueError:
                fps = 2
        else:
            fps = 2
        
        demo.run_continuous_detection(fps=fps)
    
    print("\nğŸ‘‹ æ£€æµ‹æ¼”ç¤ºç»“æŸ")


if __name__ == "__main__":
    main()
